[{"model": "ranking.publisher", "pk": 1, "fields": {"name": "Facebook Research"}}, {"model": "ranking.publisher", "pk": 2, "fields": {"name": "Korea Academic Institute of Science and Technology"}}, {"model": "ranking.publisher", "pk": 3, "fields": {"name": "Massachusetts Institute of Technology"}}, {"model": "ranking.publisher", "pk": 4, "fields": {"name": "Carnegie Mellon University"}}, {"model": "ranking.publisher", "pk": 5, "fields": {"name": "California Technology University"}}, {"model": "ranking.paper", "pk": 1, "fields": {"title": "Mining Procedures from Technical Support Documents", "slug": "mining-procedures-from-technical-support", "author": "Abhirut Gupta, Abhay Khosla, Gautam Singh, Gargi Dasgupta", "year": 2018, "publisher": 1, "abstract": "Guided troubleshooting is an inherent task in the domain of technical support services. When a customer experiences an issue with the functioning of a technical service or a product, an expert user helps guide the customer through a set of steps comprising a troubleshooting procedure. The objective is to identify the source of the problem through a set of diagnostic steps and observations, and arrive at a resolution. Procedures containing these set of diagnostic steps and observations in response to different problems are common artifacts in the body of technical support documentation. The ability to use machine learning and linguistics to understand and leverage these procedures for applications like intelligent chatbots or robotic process automation, is crucial. Existing research on question answering or intelligent chatbots does not look within procedures or deep-understand them. In this paper, we outline a system for mining procedures from technical support documents. We create models for solving important subproblems like extraction of procedures, identifying decision points within procedures, identifying blocks of instructions corresponding to these decision points and mapping instructions within a decision block. We also release a dataset containing our manual annotations on publicly available support documents, to promote further research on the problem.", "score": 84.0, "registered": "2018-05-27T13:51:15.691Z"}}, {"model": "ranking.paper", "pk": 2, "fields": {"title": "Meta-Gradient Reinforcement Learning", "slug": "meta-gradient-reinforcement", "author": "Zhongwen Xu, Hado van Hasselt, David Silver", "year": 2018, "publisher": 2, "abstract": "The goal of reinforcement learning algorithms is to estimate and/or optimise the value function. However, unlike supervised learning, no teacher or oracle is available to provide the true value function. Instead, the majority of reinforcement learning algorithms estimate and/or optimise a proxy for the value function. This proxy is typically based on a sampled and bootstrapped approximation to the true value function, known as a return. The particular choice of return is one of the chief components determining the nature of the algorithm: the rate at which future rewards are discounted; when and how values should be bootstrapped; or even the nature of the rewards themselves. It is well-known that these decisions are crucial to the overall success of RL algorithms. We discuss a gradient-based meta-learning algorithm that is able to adapt the nature of the return, online, whilst interacting and learning from the environment. When applied to 57 games on the Atari 2600 environment over 200 million frames, our algorithm achieved a new state-of-the-art performance.", "score": 90.0, "registered": "2018-05-27T13:51:54.917Z"}}, {"model": "ranking.paper", "pk": 3, "fields": {"title": "R-VQA: Learning Visual Relation Facts with Semantic Attention for Visual Question Answering", "slug": "r-vqa-learning-visual-relation-facts-with", "author": "Pan Lu, Lei Ji, Wei Zhang, Nan Duan, Ming Zhou, Jianyong Wang", "year": 2018, "publisher": 3, "abstract": "Recently, Visual Question Answering (VQA) has emerged as one of the most significant tasks in multimodal learning as it requires understanding both visual and textual modalities. Existing methods mainly rely on extracting image and question features to learn their joint feature embedding via multimodal fusion or attention mechanism. Some recent studies utilize external VQA-independent models to detect candidate entities or attributes in images, which serve as semantic knowledge complementary to the VQA task. However, these candidate entities or attributes might be unrelated to the VQA task and have limited semantic capacities. To better utilize semantic knowledge in images, we propose a novel framework to learn visual relation facts for VQA. Specifically, we build up a Relation-VQA (R-VQA) dataset based on the Visual Genome dataset via a semantic similarity module, in which each data consists of an image, a corresponding question, a correct answer and a supporting relation fact. A well-defined relation detector is then adopted to predict visual question-related relation facts. We further propose a multi-step attention model composed of visual attention and semantic attention sequentially to extract related visual knowledge and semantic knowledge. We conduct comprehensive experiments on the two benchmark datasets, demonstrating that our model achieves state-of-the-art performance and verifying the benefit of considering visual relation facts.", "score": 53.0, "registered": "2018-05-27T13:52:33.912Z"}}, {"model": "ranking.paper", "pk": 4, "fields": {"title": "Learning and Testing Causal Models with Interventions", "slug": "learning-and-testing-causal-models-with", "author": "Jayadev Acharya, Arnab Bhattacharyya, Constantinos Daskalakis, Saravanan Kandasamy", "year": 2018, "publisher": 4, "abstract": "We consider testing and learning problems on causal Bayesian networks as defined by Pearl (Pearl, 2009). Given a causal Bayesian network M on a graph with n discrete variables and bounded in-degree and bounded `confounded components', we show that O(logn) interventions on an unknown causal Bayesian network X on the same graph, and O~(n/\u03f52) samples per intervention, suffice to efficiently distinguish whether X=M or whether there exists some intervention under which X and M are farther than \u03f5 in total variation distance. We also obtain sample/time/intervention efficient algorithms for: (i) testing the identity of two unknown causal Bayesian networks on the same graph; and (ii) learning a causal Bayesian network on a given graph. Although our algorithms are non-adaptive, we show that adaptivity does not help in general: \u03a9(logn) interventions are necessary for testing the identity of two unknown causal Bayesian networks on the same graph, even adaptively. Our algorithms are enabled by a new subadditivity inequality for the squared Hellinger distance between two causal Bayesian networks.", "score": 72.0, "registered": "2018-05-27T13:53:27.971Z"}}, {"model": "ranking.paper", "pk": 5, "fields": {"title": "Been There, Done That: Meta-Learning with Episodic Recall", "slug": "been-there-done-that-meta-learning-with-episodic", "author": "Samuel Ritter, Jane X. Wang, Zeb Kurth-Nelson, Siddhant M. Jayakumar, Charles Blundell, Razvan Pascanu, Matthew Botvinick", "year": 2018, "publisher": 5, "abstract": " Meta-learning agents excel at rapidly learning new tasks from open-ended taskdistributions; yet, they forget what they learn about each task as soon as thenext begins. When tasks reoccur - as they do in natural environments -metalearning agents must explore again instead of immediately exploitingpreviously discovered solutions. We propose a formalism for generatingopen-ended yet repetitious environments, then develop a meta-learningarchitecture for solving these environments. This architecture melds thestandard LSTM working memory with a differentiable neural episodic memory. Weexplore the capabilities of agents with this episodic LSTM in fivemeta-learning environments with reoccurring tasks, ranging from bandits tonavigation and stochastic sequential decision problems.", "score": 55.0, "registered": "2018-05-27T14:13:16.862Z"}}, {"model": "ranking.paper", "pk": 6, "fields": {"title": "Forming IDEAS Interactive Data Exploration & Analysis System", "slug": "forming-ideas-interactive-data-exploration", "author": "Robert A. Bridges, Maria A. Vincent, Kelly M. T. Huffer, John R. Goodall, Jessie D. Jamieson, Zachary Burch", "year": 2018, "publisher": 1, "abstract": " Modern cyber security operations collect an enormous amount of logging andalerting data. While analysts have the ability to query and compute simplestatistics and plots from their data, current analytical tools are too simpleto admit deep understanding. To detect advanced and novel attacks, analyststurn to manual investigations. While commonplace, current investigations aretime-consuming, intuition-based, and proving insufficient. Our hypothesis isthat arming the analyst with easy-to-use data science tools will increase theirwork efficiency, provide them with the ability to resolve hypotheses withscientific inquiry of their data, and support their decisions with evidenceover intuition. To this end, we present our work to build IDEAS (InteractiveData Exploration and Analysis System). We present three real-world use-casesthat drive the system design from the algorithmic capabilities to the userinterface. Finally, a modular and scalable software architecture is discussedalong with plans for our pilot deployment with a security operation command.", "score": 95.0, "registered": "2018-05-27T14:13:44.596Z"}}, {"model": "ranking.paper", "pk": 7, "fields": {"title": "Learning compositionally through attentive guidance", "slug": "learning-compositionally-through-attentive", "author": "Dieuwke Hupkes, Anand Singh, Kris Korrel, German Kruszewski, Elia Bruni", "year": 2018, "publisher": 2, "abstract": " In this paper, we introduce Attentive Guidance (AG), a new mechanism todirect a sequence to sequence model equipped with attention to find morecompositional solutions that generalise even in cases where the training andtesting distribution strongly diverge. We test AG on two tasks, devisedprecisely to asses the composi- tional capabilities of neural models and showhow vanilla sequence to sequence models with attention overfit the trainingdistribution, while the guided versions come up with compositional solutionsthat, in some cases, fit the training and testing distributions equally well.AG is a simple and intuitive method to provide a learning bias to a sequence tosequence model without the need of including extra components, that we believeallows to inject a component in the training process which is also present inhuman learning: guidance.", "score": 56.0, "registered": "2018-05-27T14:14:15.150Z"}}, {"model": "ranking.paper", "pk": 8, "fields": {"title": "Global-Locally Self-Attentive Dialogue State Tracker", "slug": "global-locally-self-attentive-dialogue-state", "author": "Victor Zhong, Caiming Xiong, Richard Socher", "year": 2018, "publisher": 3, "abstract": " Dialogue state tracking, which estimates user goals and requests given thedialogue context, is an essential part of task-oriented dialogue systems. Inthis paper, we propose the Global-Locally Self-Attentive Dialogue State Tracker(GLAD), which learns representations of the user utterance and previous systemactions with global-local modules. Our model uses global modules to shareparameters between estimators for different types (called slots) of dialoguestates, and uses local modules to learn slot-specific features. We show thatthis significantly improves tracking of rare states and achievesstate-of-the-art performance on the WoZ and DSTC2 state tracking tasks. GLADobtains 88.1% joint goal accuracy and 97.1% request accuracy on WoZ,outperforming prior work by 3.7% and 5.5%. On DSTC2, our model obtains 74.5%joint goal accuracy and 97.5% request accuracy, outperforming prior work by1.1% and 1.0%.", "score": 93.0, "registered": "2018-05-27T14:14:39.037Z"}}, {"model": "ranking.paper", "pk": 9, "fields": {"title": "SOSELETO: A Unified Approach to Transfer Learning and Training with  Noisy Labels", "slug": "soseleto-a-unified-approach-to-transfer-learning", "author": "Or Litany, Daniel Freedman", "year": 2018, "publisher": 4, "abstract": " We present SOSELETO (SOurce SELEction for Target Optimization), a new methodfor exploiting a source dataset to solve a classification problem on a targetdataset. SOSELETO is based on the following simple intuition: some sourceexamples are more informative than others for the target problem. To capturethis intuition, source samples are each given weights; these weights are solvedfor jointly with the source and target classification problems via a bileveloptimization scheme. The target therefore gets to choose the source sampleswhich are most informative for its own classification task. Furthermore, thebilevel nature of the optimization acts as a kind of regularization on thetarget, mitigating overfitting. SOSELETO may be applied to both classictransfer learning, as well as the problem of training on datasets with noisylabels; we show state of the art results on both of these problems.", "score": 77.0, "registered": "2018-05-27T14:15:10.000Z"}}, {"model": "ranking.paper", "pk": 10, "fields": {"title": "A0C: Alpha Zero in Continuous Action Space", "slug": "a0c-alpha-zero-in-continuous-action", "author": "Thomas M. Moerland, Joost Broekens, Aske Plaat, Catholijn M. Jonker", "year": 2018, "publisher": 5, "abstract": " A core novelty of Alpha Zero is the interleaving of tree search and deeplearning, which has proven very successful in board games like Chess, Shogi andGo. These games have a discrete action space. However, many real-worldreinforcement learning domains have continuous action spaces, for example inrobotic control, navigation and self-driving cars. This paper presents thenecessary theoretical extensions of Alpha Zero to deal with continuous actionspace. We also provide some preliminary experiments on the Pendulum swing-uptask, empirically showing the feasibility of our approach. Thereby, this workprovides a first step towards the application of iterated search and learningin domains with a continuous action space.", "score": 81.0, "registered": "2018-05-27T14:15:31.244Z"}}, {"model": "ranking.paper", "pk": 11, "fields": {"title": "Intelligent Trainer for Model-Based Reinforcement Learning", "slug": "intelligent-trainer-for-model-based-reinforcement", "author": "Yuanlong Li, Linsen Dong, Yonggang Wen, Kyle Guan", "year": 2017, "publisher": 1, "abstract": " Model-based deep reinforcement learning (DRL) algorithm uses the sampled datafrom a real environment to learn the underlying system dynamics to construct anapproximate cyber environment. By using the synthesized data generated from thecyber environment to train the target controller, the training cost can bereduced significantly. In current research, issues such as the applicability ofapproximate model and the strategy to sample and train from the real and cyberenvironment have not been fully investigated. To address these issues, wepropose to utilize an intelligent trainer to properly use the approximate modeland control the sampling and training procedure in the model-based DRL. To doso, we package the training process of a model-based DRL as a standard RLenvironment, and design an RL trainer to control the training process. Thetrainer has three control actions: the first action controls where to sample inthe real and cyber environment; the second action determines how many datashould be sampled from the cyber environment and the third action controls howmany times the cyber data should be used to train the target controller. Theseactions would be controlled manually if without the trainer. The proposedframework is evaluated on five different tasks of OpenAI gym and the testresults show that the proposed trainer achieves significant better performancethan a fixed parameter model-based RL baseline algorithm. In addition, wecompare the performance of the intelligent trainer to a random trainer andprove that the intelligent trainer can indeed learn on the fly. The proposedtraining framework can be extended to more control actions with moresophisticated trainer design to further reduce the tweak cost of model-based RLalgorithms.", "score": 68.0, "registered": "2018-05-27T14:15:58.824Z"}}, {"model": "ranking.paper", "pk": 12, "fields": {"title": "A Practical Algorithm for Distributed Clustering and Outlier Detection", "slug": "a-practical-algorithm-for-distributed-clustering", "author": "Jiecao Chen, Erfan Sadeqi Azer, Qin Zhang", "year": 2017, "publisher": 2, "abstract": " We study the classic kk-means/median clustering, which are fundamentalproblems in unsupervised learning, in the setting where data are partitionedacross multiple sites, and where we are allowed to discard a small portion ofthe data by labeling them as outliers. We propose a simple approach based onconstructing small summary for the original dataset. The proposed method istime and communication efficient, has good approximation guarantees, and canidentify the global outliers effectively. To the best of our knowledge, this isthe first practical algorithm with theoretical guarantees for distributedclustering with outliers. Our experiments on both real and synthetic data havedemonstrated the clear superiority of our algorithm against all the baselinealgorithms in almost all metrics.", "score": 69.0, "registered": "2018-05-27T14:16:16.842Z"}}, {"model": "ranking.paper", "pk": 13, "fields": {"title": "Hierarchical Clustering with Structural Constraints", "slug": "hierarchical-clustering-with-structural", "author": "Vaggos Chatziafratis, Rad Niazadeh, Moses Charikar", "year": 2017, "publisher": 3, "abstract": " We study the classic kk-means/median clustering, which are fundamentalproblems in unsupervised learning, in the setting where data are partitionedacross multiple sites, and where we are allowed to discard a small portion ofthe data by labeling them as outliers. We propose a simple approach based onconstructing small summary for the original dataset. The proposed method istime and communication efficient, has good approximation guarantees, and canidentify the global outliers effectively. To the best of our knowledge, this isthe first practical algorithm with theoretical guarantees for distributedclustering with outliers. Our experiments on both real and synthetic data havedemonstrated the clear superiority of our algorithm against all the baselinealgorithms in almost all metrics.", "score": 71.0, "registered": "2018-05-27T14:16:30.330Z"}}, {"model": "ranking.paper", "pk": 14, "fields": {"title": "Hierarchical Clustering with Structural Constraints", "slug": "hierarchical-clustering-with-structural", "author": "Vaggos Chatziafratis, Rad Niazadeh, Moses Charikar", "year": 2017, "publisher": 4, "abstract": " Hierarchical clustering is a popular unsupervised data analysis method. Formany real-world applications, we would like to exploit prior information aboutthe data that imposes constraints on the clustering hierarchy, and is notcaptured by the set of features available to the algorithm. This gives rise tothe problem of \"hierarchical clustering with structural constraints\".Structural constraints pose major challenges for bottom-up approaches likeaverage/single linkage and even though they can be naturally incorporated intotop-down divisive algorithms, no formal guarantees exist on the quality oftheir output. In this paper, we provide provable approximation guarantees fortwo simple top-down algorithms, using a recently introduced optimizationviewpoint of hierarchical clustering with pairwise similarity information[Dasgupta, 2016]. We show how to find good solutions even in the presence ofconflicting prior information, by formulating a \"constraint-basedregularization\" of the objective. Finally, we explore a variation of thisobjective for dissimilarity information [Cohen-Addad et al., 2018] and improveupon current techniques.", "score": 100.0, "registered": "2018-05-27T14:16:59.134Z"}}, {"model": "ranking.paper", "pk": 15, "fields": {"title": "Cautious Deep Learning", "slug": "cautious-deep", "author": "Yotam Hechtlinger, Barnab\u00e1s P\u00f3czos, Larry Wasserman", "year": 2017, "publisher": 5, "abstract": " Most classifiers operate by selecting the maximum of an estimate of theconditional distribution p(y|x)p(y|x) where xx stands for the features of theinstance to be classified and yy denotes its label. This often results in ahubristic bias: overconfidence in the assignment of a definite label. Usually,the observations are concentrated on a small volume but the classifier providesdefinite predictions for the entire space. We propose constructing conformalprediction sets [vovk2005algorithmic] which contain a set of labels rather thana single label. These conformal prediction sets contain the true label withprobability 1\u2212\u03b11-\u0007lpha. Our construction is based on p(x|y)p(x|y) rather thanp(y|x)p(y|x) which results in a classifier that is very cautious: it outputs thenull set - meaning `I don't know' --- when the object does not resemble thetraining examples. An important property of our approach is that classes can beadded or removed without having to retrain the classifier. We demonstrate theperformance on the ImageNet ILSVRC dataset using high dimensional featuresobtained from state of the art convolutional neural networks.", "score": 68.0, "registered": "2018-05-27T14:17:15.363Z"}}, {"model": "ranking.paper", "pk": 16, "fields": {"title": "Adaptive Stochastic Gradient Langevin Dynamics: Taming Convergence and  Saddle Point Escape Time", "slug": "adaptive-stochastic-gradient-langevin-dynamics", "author": "Hejian Sang, Jia Liu", "year": 2017, "publisher": 1, "abstract": " In this paper, we propose a new adaptive stochastic gradient Langevindynamics (ASGLD) algorithmic framework and its two specialized versions, namelyadaptive stochastic gradient (ASG) and adaptive gradient Langevindynamics(AGLD), for non-convex optimization problems. All proposed algorithmscan escape from saddle points with at most O(logd)O(\\log d) iterations, which isnearly dimension-free. Further, we show that ASGLD and ASG converge to a localminimum with at most O(logd/\u03f54)O(\\log d/\\epsilon^4) iterations. Also, ASGLD with fullgradients or ASGLD with a slowly linearly increasing batch size converge to alocal minimum with iterations bounded by O(logd/\u03f52)O(\\log d/\\epsilon^2), whichoutperforms existing first-order methods.", "score": 94.0, "registered": "2018-05-27T14:18:06.186Z"}}, {"model": "ranking.paper", "pk": 17, "fields": {"title": "Coordinating Collaborative Chat in Massive Open Online Courses", "slug": "coordinating-collaborative-chat-in-massive-open", "author": "Gaurav Singh Tomar, Sreecharan Sankaranarayanan, Xu Wang, Carolyn Penstein Ros\u00e9", "year": 2017, "publisher": 2, "abstract": " An earlier study of a collaborative chat intervention in a Massive OpenOnline Course (MOOC) identified negative effects on attrition stemming from arequirement for students to be matched with exactly one partner prior tobeginning the activity. That study raised questions about how to orchestrate acollaborative chat intervention in a MOOC context in order to provide thebenefit of synchronous social engagement without the coordination difficulties.In this paper we present a careful analysis of an intervention designed toovercome coordination difficulties by welcoming students into the chat on arolling basis as they arrive rather than requiring them to be matched with apartner before beginning. The results suggest the most positive impact whenexperiencing a chat with exactly one partner rather than more or less. Aqualitative analysis of the chat data reveals differential experiences betweenthese configurations that suggests a potential explanation for the effect andraises questions for future research.", "score": 91.0, "registered": "2018-05-27T14:18:16.779Z"}}, {"model": "ranking.paper", "pk": 18, "fields": {"title": "A distinct approach to diagnose Dengue Fever with the help of Soft Set  Theory", "slug": "a-distinct-approach-to-diagnose-dengue-fever-with", "author": "Syeda fariha Bukhari, Maaz Amjad", "year": 2017, "publisher": 3, "abstract": " Mathematics has played a substantial role to revolutionize the medicalscience. Intelligent systems based on mathematical theories have proved to beefficient in diagnosing various diseases. In this paper, we used an expertsystem based on soft set theory and fuzzy set theory named as a soft expertsystem to diagnose tropical disease dengue. The objective to use soft expertsystem is to predict the risk level of a patient having dengue fever by usinginput variables like age, TLC, SGOT, platelets count and blood pressure. Theproposed method explicitly demonstrates the exact percentage of the risk levelof dengue fever automatically circumventing for all possible (medical)imprecisions.", "score": 57.0, "registered": "2018-05-27T14:18:33.125Z"}}, {"model": "ranking.paper", "pk": 19, "fields": {"title": "Generalisation of structural knowledge in the Hippocampal-Entorhinal  system", "slug": "generalisation-of-structural-knowledge-in-the", "author": "James C. R. Whittington, Timothy H. Muller, Caswell Barry, Timothy E. J. Behrens", "year": 2017, "publisher": 4, "abstract": " A central problem to understanding intelligence is the concept ofgeneralisation. This allows previously learnt structure to be exploited tosolve tasks in novel situations differing in their particularities. We takeinspiration from neuroscience, specifically the Hippocampal-Entorhinal system(containing place and grid cells), known to be important for generalisation. Wepropose that to generalise structural knowledge, the representations of thestructure of the world, i.e. how entities in the world relate to each other,need to be separated from representations of the entities themselves. We show,under these principles, artificial neural networks embedded with hierarchy andfast Hebbian memory, can learn the statistics of memories, generalisestructural knowledge, and also exhibit neuronal representations mirroring thosefound in the brain. We experimentally support model assumptions, showing apreserved relationship between grid and place cells across environments.", "score": 56.0, "registered": "2018-05-27T14:18:46.828Z"}}, {"model": "ranking.paper", "pk": 20, "fields": {"title": "A Psychopathological Approach to Safety Engineering in AI and AGI", "slug": "a-psychopathological-approach-to-safety", "author": "Vahid Behzadan, Arslan Munir, Roman V. Yampolskiy", "year": 2017, "publisher": 5, "abstract": " The complexity of dynamics in AI techniques is already approaching that ofcomplex adaptive systems, thus curtailing the feasibility of formalcontrollability and reachability analysis in the context of AI safety. Itfollows that the envisioned instances of Artificial General Intelligence (AGI)will also suffer from challenges of complexity. To tackle such issues, wepropose the modeling of deleterious behaviors in AI and AGI as psychologicaldisorders, thereby enabling the employment of psychopathological approaches toanalysis and control of misbehaviors. Accordingly, we present a discussion onthe feasibility of the psychopathological approaches to AI safety, and proposegeneral directions for research on modeling, diagnosis, and treatment ofpsychological disorders in AGI.", "score": 79.0, "registered": "2018-05-27T14:19:07.042Z"}}, {"model": "ranking.paper", "pk": 21, "fields": {"title": "Letting Emotions Flow: Success Prediction by Modeling the Flow of  Emotions in Books", "slug": "letting-emotions-flow-success-prediction-by", "author": "Suraj Maharjan, Sudipta Kar, Manuel Montes-y-Gomez, Fabio A. Gonzalez, Thamar Solorio", "year": 2016, "publisher": 1, "abstract": " Books have the power to make us feel happiness, sadness, pain, surprise, orsorrow. An author's dexterity in the use of these emotions captivates readersand makes it difficult for them to put the book down. In this paper, we modelthe flow of emotions over a book using recurrent neural networks and quantifyits usefulness in predicting success in books. We obtained the best weightedF1-score of 69% for predicting books' success in a multitask setting(simultaneously predicting success and genre of books).", "score": 51.0, "registered": "2018-05-27T14:21:09.935Z"}}, {"model": "ranking.paper", "pk": 22, "fields": {"title": "Crowd-Labeling Fashion Reviews with Quality Control", "slug": "crowd-labeling-fashion-reviews-with-quality", "author": "Iurii Chernushenko, Felix A. Gers, Alexander L\u00f6ser, Alessandro Checco", "year": 2016, "publisher": 2, "abstract": " We present a new methodology for high-quality labeling in the fashion domainwith crowd workers instead of experts. We focus on the Aspect-Based SentimentAnalysis task. Our methods filter out inaccurate input from crowd workers butwe preserve different worker labeling to capture the inherent high variabilityof the opinions. We demonstrate the quality of labeled data based on Facebook'sFastText framework as a baseline.", "score": 79.0, "registered": "2018-05-27T14:31:10.078Z"}}, {"model": "ranking.paper", "pk": 23, "fields": {"title": "Native Language Cognate Effects on Second Language Lexical Choice", "slug": "native-language-cognate-effects-on-second", "author": "Ella Rabinovich, Yulia Tsvetkov, Shuly Wintner", "year": 2016, "publisher": 3, "abstract": " We present a computational analysis of cognate effects on the spontaneouslinguistic productions of advanced non-native speakers. Introducing a largecorpus of highly competent non-native English speakers, and using a set ofcarefully selected lexical items, we show that the lexical choices ofnon-natives are affected by cognates in their native language. This effect isso powerful that we are able to reconstruct the phylogenetic language tree ofthe Indo-European language family solely from the frequencies of specificlexical items in the English of authors with various native languages. Wequantitatively analyze non-native lexical choice, highlighting cognatefacilitation as one of the important phenomena shaping the language ofnon-native speakers.", "score": 60.0, "registered": "2018-05-27T14:31:23.451Z"}}, {"model": "ranking.paper", "pk": 24, "fields": {"title": "Modeling Interpersonal Influence of Verbal Behavior in Couples Therapy  Dyadic Interactions", "slug": "modeling-interpersonal-influence-of-verbal", "author": "Sandeep Nallan Chakravarthula, Brian Baucom, Panayiotis Georgiou", "year": 2016, "publisher": 4, "abstract": " Dyadic interactions among humans are marked by speakers continuouslyinfluencing and reacting to each other in terms of responses and behaviors,among others. Understanding how interpersonal dynamics affect behavior isimportant for successful treatment in psychotherapy domains. Traditionalschemes that automatically identify behavior for this purpose have often lookedat only the target speaker. In this work, we propose a Markov model of how atarget speaker's behavior is influenced by their own past behavior as well astheir perception of their partner's behavior, based on lexical features. Apartfrom incorporating additional potentially useful information, our model canalso control the degree to which the partner affects the target speaker. Weevaluate our proposed model on the task of classifying Negative behavior inCouples Therapy and show that it is more accurate than the single-speakermodel. Furthermore, we investigate the degree to which the optimal influencerelates to how well a couple does on the long-term, via relating torelationship outcomes", "score": 50.0, "registered": "2018-05-27T14:31:36.822Z"}}, {"model": "ranking.paper", "pk": 25, "fields": {"title": "Embedding Syntax and Semantics of Prepositions via Tensor Decomposition", "slug": "embedding-syntax-and-semantics-of-prepositions", "author": "Hongyu Gong, Suma Bhat, Pramod Viswanath", "year": 2016, "publisher": 5, "abstract": " Prepositions are among the most frequent words in English and play complexroles in the syntax and semantics of sentences. Not surprisingly, they posewell-known difficulties in automatic processing of sentences (prepositionalattachment ambiguities and idiosyncratic uses in phrases). Existing methods onpreposition representation treat prepositions no different from content words(e.g., word2vec and GloVe). In addition, recent studies aiming at solvingprepositional attachment and preposition selection problems depend heavily onexternal linguistic resources and use dataset-specific word representations. Inthis paper we use word-triple counts (one of the triples being a preposition)to capture a preposition's interaction with its attachment and complement. Wethen derive preposition embeddings via tensor decomposition on a largeunlabeled corpus. We reveal a new geometry involving Hadamard products andempirically demonstrate its utility in paraphrasing phrasal verbs. Furthermore,our preposition embeddings are used as simple features in two challengingdownstream tasks: preposition selection and prepositional attachmentdisambiguation. We achieve results comparable to or better than thestate-of-the-art on multiple standardized datasets.", "score": 95.0, "registered": "2018-05-27T14:32:13.519Z"}}, {"model": "ranking.paper", "pk": 26, "fields": {"title": "Scoring Lexical Entailment with a Supervised Directional Similarity  Network", "slug": "scoring-lexical-entailment-with-a-supervised", "author": "Marek Rei, Daniela Gerz, Ivan Vuli\u0107", "year": 2016, "publisher": 1, "abstract": " We present the Supervised Directional Similarity Network (SDSN), a novelneural architecture for learning task-specific transformation functions on topof general-purpose word embeddings. Relying on only a limited amount ofsupervision from task-specific scores on a subset of the vocabulary, ourarchitecture is able to generalise and transform a general-purposedistributional vector space to model the relation of lexical entailment.Experiments show excellent performance on scoring graded lexical entailment,raising the state-of-the-art on the HyperLex dataset by approximately 25%.", "score": 73.0, "registered": "2018-05-27T14:32:28.038Z"}}, {"model": "ranking.paper", "pk": 27, "fields": {"title": "Working Memory Networks: Augmenting Memory Networks with a Relational  Reasoning Module", "slug": "working-memory-networks-augmenting-memory", "author": "Juan Pavez, H\u00e9ctor Allende, H\u00e9ctor Allende-Cid", "year": 2016, "publisher": 2, "abstract": " During the last years, there has been a lot of interest in achieving somekind of complex reasoning using deep neural networks. To do that, models likeMemory Networks (MemNNs) have combined external memory storages and attentionmechanisms. These architectures, however, lack of more complex reasoningmechanisms that could allow, for instance, relational reasoning. RelationNetworks (RNs), on the other hand, have shown outstanding results in relationalreasoning tasks. Unfortunately, their computational cost grows quadraticallywith the number of memories, something prohibitive for larger problems. Tosolve these issues, we introduce the Working Memory Network, a MemNNarchitecture with a novel working memory storage and reasoning module. Ourmodel retains the relational reasoning abilities of the RN while reducing itscomputational complexity from quadratic to linear. We tested our model on thetext QA dataset bAbI and the visual QA dataset NLVR. In the jointly trainedbAbI-10k, we set a new state-of-the-art, achieving a mean error of less than0.5%. Moreover, a simple ensemble of two of our models solves all 20 tasks inthe joint version of the benchmark.", "score": 100.0, "registered": "2018-05-27T14:32:38.961Z"}}, {"model": "ranking.paper", "pk": 28, "fields": {"title": "Auto-Detection of Safety Issues in Baby Products", "slug": "auto-detection-of-safety-issues-in-baby", "author": "Graham Bleaney, Matthew Kuzyk, Julian Man, Hossein Mayanloo, H.R.Tizhoosh", "year": 2016, "publisher": 3, "abstract": " Every year, thousands of people receive consumer product related injuries.Research indicates that online customer reviews can be processed toautonomously identify product safety issues. Early identification of safetyissues can lead to earlier recalls, and thus fewer injuries and deaths. Adataset of product reviews from Amazon.com was compiled, along with\\emph{SaferProducts.gov} complaints and recall descriptions from the ConsumerProduct Safety Commission (CPSC) and European Commission Rapid Alert system. Asystem was built to clean the collected text and to extract relevant features.Dimensionality reduction was performed by computing feature relevance through aRandom Forest and discarding features with low information gain. Variousclassifiers were analyzed, including Logistic Regression, SVMs,Na{\"i}ve-Bayes, Random Forests, and an Ensemble classifier. Experimentationwith various features and classifier combinations resulted in a logisticregression model with 70.2\\% precision in the top 50 reviews surfaced. Thisclassifier outperforms all benchmarks set by related literature and consumerproduct safety professionals.", "score": 51.0, "registered": "2018-05-27T14:32:55.502Z"}}, {"model": "ranking.paper", "pk": 29, "fields": {"title": "Corpus Conversion Service: A machine learning platform to ingest  documents at scale [Poster abstract]", "slug": "corpus-conversion-service-a-machine-learning", "author": "Peter W J Staar, Michele Dolfi, Christoph Auer, Costas Bekas", "year": 2016, "publisher": 4, "abstract": " Over the past few decades, the amount of scientific articles and technicalliterature has increased exponentially in size. Consequently, there is a greatneed for systems that can ingest these documents at scale and make theircontent discoverable. Unfortunately, both the format of these documents (e.g.the PDF format or bitmap images) as well as the presentation of the data (e.g.complex tables) make the extraction of qualitative and quantitive dataextremely challenging. We present a platform to ingest documents at scale whichis powered by Machine Learning techniques and allows the user to train custommodels on document collections. We show precision/recall results greater than97% with regard to conversion to structured formats, as well as scalingevidence for each of the microservices constituting the platform.", "score": 71.0, "registered": "2018-05-27T14:33:09.536Z"}}, {"model": "ranking.paper", "pk": 30, "fields": {"title": "DINFRA: A One Stop Shop for Computing Multilingual Semantic Relatedness", "slug": "dinfra-a-one-stop-shop-for-computing-multilingual", "author": "Siamak Barzegar, Juliano Efson Sales, Andre Freitas, Siegfried Handschuh, Brian Davis", "year": 2016, "publisher": 5, "abstract": " This demonstration presents an infrastructure for computing multilingualsemantic relatedness and correlation for twelve natural languages by usingthree distributional semantic models (DSMs). Our demonsrator - DInfra(Distributional Infrastructure) provides researchers and developers with ahighly useful platform for processing large-scale corpora and conductingexperiments with distributional semantics. We integrate several multilingualDSMs in our webservice so the end user can obtain a result without worryingabout the complexities involved in building DSMs. Our webservice allows theusers to have easy access to a wide range of comparisons of DSMs with differentparameters. In addition, users can configure and access DSM parameters using aneasy to use API.", "score": 69.0, "registered": "2018-05-27T14:33:24.541Z"}}]